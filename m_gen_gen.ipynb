{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Playing with RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#@formatter:off\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#@formatter:on\n",
    "\n",
    "import os\n",
    "from src.models.RNN import RNN\n",
    "from src.Sampling import Sampling\n",
    "from src.TextGeneration import TextGeneration\n",
    "from src.utils.Utils import Utils\n",
    "\n",
    "Utils.tensorflow_shutup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dry Run"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [TextGeneration]:\tmodel_func=get_LSTM\tverbosity=1\n"
     ]
    }
   ],
   "source": [
    "gen_rnn = TextGeneration(config=config, model_func=RNN.get_RNN, verbosity=1)\n",
    "gen_lstm = TextGeneration(config=config, model_func=RNN.get_RNN, verbosity=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading a Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No models found in models/beatles",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3821281/1490001560.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Load model from models/beatles/model_LSTM_beatles_WS-35_ST-3_BS-2500_HS-256-512_DR-0.5_LR-0.001\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mgenerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"models\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"beatles\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/jupyter/COSC525_TEAM/project4/src/TextGeneration.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(self, path, index)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mmodels\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 183\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"No models found in {path}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    185\u001B[0m         \u001B[0moptions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: No models found in models/beatles"
     ]
    }
   ],
   "source": [
    "gen_rnn.load_model(os.path.join(\"models\", \"beatles\"), 0)\n",
    "gen_lstm.load_model(os.path.join(\"models\", \"beatles\"), 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating Sequences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gen(gen_model, sampling, temp=0.75, seed=0):\n",
    "    prompt = \"i swear, man, this ain't\"\n",
    "    print(\"=\" * 80)\n",
    "    generated = gen_rnn.predict(prompt, pred_len=500, temp=temp, include_prompt=True,\n",
    "                                sampling_method=sampling, seed=seed)\n",
    "    print(\"-\" * 80)\n",
    "    print(generated)\n",
    "    print(\"=\" * 80)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Greedy Search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "# [TextGeneration - predict]:\tprompt_len=24\tnum_chars=500\n",
      "Old Function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating...: 100%|██████████| 500/500 [00:17<00:00, 28.50it/s, char=[b'u']]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "i swear, man, this ain't got nothing to say but it’s o.k.\n",
      "good morning, good morning...\n",
      "people running round it's five o’clock.\n",
      "everywhere in town with you\n",
      "i don’t know why you say goodbye, i say hello\n",
      "hello hello\n",
      "i don't know why you say goodbye, i say hello\n",
      "hello hello\n",
      "i don't know why you say goodbye, i say hello\n",
      "hello hello\n",
      "i don't know why you say goodbye, i say hello\n",
      "hello hello\n",
      "i don't know why you say goodbye, i say hello\n",
      "hello hello\n",
      "i don't know why you say goodbye, i say hello\n",
      "hello hello\n",
      "i don't know why you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen(gen_rnn, Sampling.greedy_search)\n",
    "gen(gen_lstm, Sampling.greedy_search)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Random Sampling w/ Temperature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "# [TextGeneration - predict]:\tprompt_len=24\tnum_chars=500\n",
      "Old Function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating...: 100%|██████████| 500/500 [00:17<00:00, 28.48it/s, char=[b'e']]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "i swear, man, this ain't no dancer.\n",
      "look out helter skelter\n",
      "helter skelter\n",
      "look out helter skelter\n",
      "helter skelter\n",
      "let me have to say that i’ve been unhappy with you\n",
      "i see no day\n",
      "if i till your feet.\n",
      "roll up to make a doe who is all belong?\n",
      "sit beside a mountain waiting for this moment to arise\n",
      "you were only waiting for this moment to arise.\n",
      "blackbird singing in the dead of night\n",
      "take these broken wings and learn to see\n",
      "all the cold and to you.\n",
      "all my loving, darling\n",
      "if you wanna dance with me\n",
      "if you wanna dance with me\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen(gen_rnn, Sampling.random_sampling)\n",
    "gen(gen_lstm, Sampling.random_sampling)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Beam Search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "# [TextGeneration - predict]:\tprompt_len=24\tnum_chars=500\n",
      "Old Function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating...: 100%|██████████| 500/500 [00:18<00:00, 27.68it/s, char=[b' ']]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "i swear, man, this ain't the kind that you can see.\n",
      "whoa, oh, these chains of love got a hold on me.\n",
      "believe me when i tell you\n",
      "i’m looking through you, you’re never weep at night i said these words to my girl,\n",
      "i have got another man\n",
      "that’s the end’a little girl\n",
      "help you should see polythene pam\n",
      "you better run for your life if you can, little girl\n",
      "and why you lied to me,\n",
      "tell me why\n",
      "you can send it here\n",
      "but i never heard it singing\n",
      "no i never heard it at all.\n",
      "would it out of my window\n",
      "you’re coming home, you’re coming \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen(gen_rnn, Sampling.beam_search)\n",
    "gen(gen_lstm, Sampling.beam_search)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}