# Papers

- [Inverse Graphics GAN: Learning to Generate 3D Shapes from Unstructured 2D Data](https://arxiv.org/pdf/2002.12674.pdf)

# Image Classification
## OpenAI CLIP
https://blog.roboflow.com/openai-clip/
https://blog.roboflow.com/how-to-use-openai-clip/

## Use-Case:
- Feed in original image => get text representation of image.
  - For example, if the input is an image of dog on a lawn, the output is "image of a dog on a lawn".

# Image Generation
## OpenAI DALL-E
https://openai.com/blog/dall-e/
https://github.com/openai/dall-e

## Use-Case:
- The user edits the original text representation => this model generates a new image.
  - For example, "image of a dog on a street" => model generates corresponding image

## Performance and Limitations

The heavy compression from the encoding process results in a noticeable loss of detail in the reconstructed images. This
renders it inappropriate for applications that require fine-grained details of the image to be preserved.

# Libraries To Use

- [Rendering 3D Images with Pytorch3d](https://towardsdatascience.com/how-to-render-3d-files-using-pytorch3d-ef9de72483f8)



## [NVIDIA's New AI: Enhance!](https://www.youtube.com/watch?v=e0yEOw6Zews)

- ğŸ“ The paper "EG3D: Efficient Geometry-aware 3D Generative Adversarial Networks" is available here:
  https://matthew-a-chan.github.io/EG3D/
- ğŸ“ The latent space material synthesis paper "Gaussian Material Synthesis" is available here:
  https://users.cg.tuwien.ac.at/zsolnai...

## [NVIDIAâ€™s New AI: Wow, Instant Neural Graphics! ğŸ¤–](https://www.youtube.com/watch?v=j8tMk-GE8hY)

- ğŸ“ #NVIDIA's paper "Instant Neural Graphics Primitives with a Multiresolution Hash Encoding" is available here:
  https://nvlabs.github.io/instant-ngp/

## [NVIDIAâ€™s New AI: Superb Details, Super Fast! ğŸ¤–](https://www.youtube.com/watch?v=eaSTGOgO-ss&t=1s)

- ğŸ“ The paper "Multimodal Conditional Image Synthesis with Product-of-Experts GANs" (#PoEGAN) is available here:
  https://deepimagination.cc/PoE-GAN/

## [Next Level Paint Simulations Are Coming! ğŸ¨ğŸ–Œï¸](https://www.youtube.com/watch?v=b2D_5G_npVI)

- ğŸ“ The paper "Practical Pigment Mixing for Digital Painting" is available here:
  https://scrtwpns.com/mixbox/

## [NVIDIAâ€™s New AI Draws Images With The Speed of Thought! âš¡](https://www.youtube.com/watch?v=Wbid5rvCGos&t=271s)

- ğŸ“ The previous paper "Semantic Image Synthesis with Spatially-Adaptive Normalization" is available here:  
  https://nvlabs.github.io/SPADE/

## [New AI: Next Level Video Editing! ğŸ¤¯](https://www.youtube.com/watch?v=MCq0x01Jmi0&t=192s)

- ğŸ“ The paper "Layered Neural Atlases for Consistent Video Editing" is available here:        
  https://layered-neural-atlases.github.io/

## [Photos Go In, Reality Comes Outâ€¦And Fast! ğŸŒ](https://www.youtube.com/watch?v=yptwRRpPEBM)

- ğŸ“ The paper "Plenoxels: Radiance Fields without Neural Networks" is available here:         
  https://alexyu.net/plenoxels/
  [Googleâ€™s New AI: This is Where Selfies Go Hyper! ğŸ¤³](https://www.youtube.com/watch?v=B-zxoJ9o7s0&t=88s)
- ğŸ“ The paper "A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields" is available
  here:      
  https://hypernerf.github.io/

## [Enhance! Super Resolution Is Here! ğŸ”](https://www.youtube.com/watch?v=WCAF3PNEc_c)

- ğŸ“ The paper "Image Super-Resolution via Iterative Refinement " is available here:
  https://iterative-refinement.github.io/
- https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement

## [This Image Is Fine. Completely Fine. ğŸ¤–](https://www.youtube.com/watch?v=BS2la3C-TYc&t=354s)

- ğŸ“ The paper "The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning"
  is available here:      
  https://attentionneuron.github.io/

## [NVIDIAâ€™s New Technique: Beautiful Models For Less! ğŸŒ²](https://www.youtube.com/watch?v=ogL-2IClOug&t=151s)

- ğŸ“ The paper "Appearance-Driven Automatic 3D Model Simplification" is available here:          
  https://research.nvidia.com/publication/2021-04_Appearance-Driven-Automatic-3D
- ğŸ“ The differentiable material synthesis paper is available here:          
  https://users.cg.tuwien.ac.at/zsolnai/gfx/photorealistic-material-learning-and-synthesis/

## [Finally, Video Stabilization That Works! ğŸ¤³](https://www.youtube.com/watch?v=v5pOsQEOsyA&t=155s)

- ğŸ“ The paper "FuSta - Hybrid Neural Fusion for Full-frame Video Stabilization" is available here:
	- Paper https://alex04072000.github.io/FuSta/
	- Code: https://github.com/alex04072000/FuSta
	- Colab: https://colab.research.google.com/drive/1l-fUzyM38KJMZyKMBWw_vu7ZUyDwgdYH?usp=sharing

## [This AI Learned To Stop Time! â±](https://www.youtube.com/watch?v=4CYI6dt1ZNY)

- ğŸ“ The paper "Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes" is available
  here: http://www.cs.cornell.edu/~zl548/NSFF/

## [This AI Makes Beautiful Videos From Your Images! ğŸŒŠ](https://www.youtube.com/watch?v=t7nO7MPcOGo&t=139s)

- ğŸ“ The paper "Animating Pictures with Eulerian Motion Fields" is available here:
  https://eulerian.cs.washington.edu/

## [3 New Things An AI Can Do With Your Photos!](https://www.youtube.com/watch?v=B8RMUSmIGCI&t=324s)

- ğŸ“ The paper "GANSpace: Discovering Interpretable GAN Controls" is available here:
  https://github.com/harskish/ganspace

- ğŸ“ Our material synthesis paper is available
  here: https://users.cg.tuwien.ac.at/zsolnai/gfx/gaussian-material-synthesis/

- ğŸ“ The font manifold paper is available here: http://vecg.cs.ucl.ac.uk/Projects/projects_fonts/projects_fonts.html

## [What Is 3D Photography? ğŸ‘](https://www.youtube.com/watch?v=BjkgyKEQbSM)

- ğŸ“ The paper "One Shot 3D Photography" is available here: https://facebookresearch.github.io/one_shot_3d_photography/

## [Enhance! Neural Supersampling is Here! ğŸ”](https://www.youtube.com/watch?v=OzHenjHBBds)

- ğŸ“ The paper "Neural Supersampling for Real-time Rendering" is available here:
  https://research.facebook.com/blog/2020/07/introducing-neural-supersampling-for-real-time-rendering/
  https://research.facebook.com/publications/neural-supersampling-for-real-time-rendering/

## [AI-Based Style Transfer For Videoâ€¦Now in Real Time!](https://www.youtube.com/watch?v=UiEaWkf3r9A)

- ğŸ“ The paper "Interactive Video Stylization Using Few-Shot Patch-Based Training" is available
  here: https://ondrejtexler.github.io/patch-based_training/

## [This AI Creates Real Scenes From Your Photos! ğŸ“·](https://www.youtube.com/watch?v=T29O-MhYALw)

- ğŸ“ The paper "NeRF in the Wild - Neural Radiance Fields for Unconstrained Photo Collections" is available here:
  https://nerf-w.github.io/

## [OpenAIâ€™s Image GPT Completes Your Images With Style!](https://www.youtube.com/watch?v=-6Xn4nKm-Qw)

- ğŸ“ The paper "Generative Pretraining from Pixels (Image GPT)" is available here:
  https://openai.com/blog/image-gpt/

## [https://www.youtube.com/watch?v=qeZMKgKJLX4](https://www.youtube.com/watch?v=qeZMKgKJLX4)

- ğŸ“ The paper "Portrait Shadow Manipulation" is available here:
  https://ceciliavision.github.io/project-pages/portrait

- ğŸ“ Our paper with Activision Blizzard on subsurface scattering is available here:
  https://users.cg.tuwien.ac.at/zsolnai/gfx/separable-subsurface-scattering-with-activision-blizzard/

## [Can an AI Learn Lip Reading?](https://www.youtube.com/watch?v=wg3upHE8qJw)

- ğŸ“ The paper "Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis" is available here:
  https://cvit.iiit.ac.in/research/projects/cvit-projects/speaking-by-observing-lip-movements

- Our earlier video on the "bag of chips" sound reconstruction is available here:
  https://www.youtube.com/watch?v=2i1hrywDwPo

## [This AI Creates Beautiful Time Lapse Videos â˜€ï¸](https://www.youtube.com/watch?v=EWKAgwgqXB4)

- ğŸ“ The paper "High-Resolution Daytime Translation Without Domain Labels" is available here:

- https://saic-mdal.github.io/HiDT/
- https://github.com/saic-mdal/HiDT

## [Neural Network Dreams About Beautiful Natural Scenes](https://www.youtube.com/watch?v=MPdj8KGZHa0)

- ğŸ“ The paper "Manipulating Attributes of Natural Scenes via Hallucination" is available here:
  https://hucvl.github.io/attribute_hallucination/

## [This AI Learned to Summarize Videos ğŸ¥](https://www.youtube.com/watch?v=bVXPnP8k6yo)

- ğŸ“ The paper "CLEVRER: CoLlision Events for Video REpresentation and Reasoning" is available here:
  http://clevrer.csail.mit.edu/
