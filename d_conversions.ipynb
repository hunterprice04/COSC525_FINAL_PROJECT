{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from varname.helpers import Wrapper\n",
    "\n",
    "from src import Config, TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataConfig(WINDOW_SIZE=5, STRIDE=3, DATA_PATH='data/example.txt')\n",
      "TrainingConfig(HIDDEN_STATE_SIZE=[], EPOCHS=0, BATCH_SIZE=0, DROPOUT=0.5, LR=0.001, SAMPLING_TEMP=0.75, BUFFER_SIZE=10000)\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"DATA\": {\n",
    "        \"WINDOW_SIZE\": 5,\n",
    "        \"STRIDE\": 3,\n",
    "        \"DATA_PATH\": os.path.join(\"data\", \"example.txt\"),\n",
    "    },\n",
    "    \"TRAINING\": {},\n",
    "}\n",
    "config = Config(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [TextDataset - init]:\tfile_name=data/example.txt\twindow_size=5\tstride=3\n",
      "# [TextDataset - read]:\n",
      "1. Reading `data/example.txt`...\n",
      "\t19 total chars in text\n",
      "# [Vocab - init]:\tlabel=example\tencoding=utf-8\n",
      "# [Embeddings - init]:\tlabel=example\tencoding=utf-8\n",
      "2. Converting __items__ to ids...\n",
      "\tids: (len=19 min=1, max=12)\n",
      "\tdata: <TensorSliceDataset shapes: (), types: tf.int64>\n",
      "3. Creating sequences...\n",
      "\tdata: <FlatMapDataset shapes: (6,), types: tf.int64>\n",
      "4. Splitting into inputs and targets...\n",
      "\tdataset_ids: <MapDataset shapes: ((5,), (5,)), types: (tf.int64, tf.int64)>\n",
      "5. One-hot encoding...\n",
      "# to_onehot -> input is <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\t-> Input is already IDs... skipping conversion\n",
      "# to_onehot -> input is <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\t-> Input is already IDs... skipping conversion\n",
      "\tdataset_oh: <MapDataset shapes: ((5, 13), (5, 13)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "dr = TextDataset(config, verbosity=2).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Validating Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. text_str =\n",
      "'hello'\n",
      "------------------------------------------------------------\n",
      "2. text_ids =\n",
      "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([6, 5, 7, 7, 8])>\n",
      "------------------------------------------------------------\n",
      "3. text_oh =\n",
      "<tf.Tensor: shape=(5, 13), dtype=int64, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])>\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is equivalent to the first sample in the dataset\n",
    "text_str = Wrapper(\"hello\")\n",
    "test_list = [text_str]\n",
    "\n",
    "# Grab the first sample from the dataset in both IDS and OH representations\n",
    "for ids, _ in dr.dataset_ids.take(1):\n",
    "    text_ids = Wrapper(ids)\n",
    "    test_list.append(text_ids)\n",
    "\n",
    "for oh, _ in dr.dataset_oh.take(1):\n",
    "    text_oh = Wrapper(oh)\n",
    "    test_list.append(text_oh)\n",
    "\n",
    "\n",
    "# Making sure that the conversions are correct\n",
    "def assert_same(x, expected):\n",
    "    # Check that the types of x and y are the same\n",
    "    print(\"-\" * 60)\n",
    "    print(\"  - Checking Types\")\n",
    "    assert type(x) == type(expected), f\"TYPES: {type(x)} != {type(expected)}\"\n",
    "    print(\"  - Checking Values\")\n",
    "    assert np.all(x == expected), f\"VALUES: {x} != {expected}\"\n",
    "\n",
    "\n",
    "def test_conversion_func(func, xvals: list, expected):\n",
    "    print(f\"# Testing {func.__name__}:\")\n",
    "    for i, x in enumerate(xvals):\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"{i + 1}. {x.name} => {func.__name__}\")\n",
    "        try:\n",
    "            x_ = func(x.value)\n",
    "            assert_same(x_, expected)\n",
    "        except Exception as e:\n",
    "            print_exception(e, x)\n",
    "    print(f\"OK: {func.__name__} passed\")\n",
    "\n",
    "\n",
    "def print_exception(e, x):\n",
    "    print(f\"  - ERROR: {e}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Type:\", type(x.value))\n",
    "    print(x.value)\n",
    "    print(\"=\" * 80)\n",
    "    raise e\n",
    "\n",
    "\n",
    "for i, v in enumerate(test_list):\n",
    "    print(f\"{i + 1}. {v.name} =\")\n",
    "    print(v)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conversion to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Testing to_string:\n",
      "================================================================================\n",
      "1. text_str => to_string\n",
      "# to_string -> input is <class 'str'>\n",
      "\t-> Input is already string... skipping conversion\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "================================================================================\n",
      "2. text_ids => to_string\n",
      "# to_string -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "# to_tfstring -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\t-> Input is already IDs... skipping conversion\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "================================================================================\n",
      "3. text_oh => to_string\n",
      "# to_string -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "# to_tfstring -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\t-> input is One-Hot Encoded; converting to IDs first...\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "OK: to_string passed\n"
     ]
    }
   ],
   "source": [
    "test_conversion_func(config.EMBED.to_string, test_list, test_list[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conversion to IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Testing to_ids:\n",
      "================================================================================\n",
      "1. text_str => to_ids\n",
      "# to_ids -> input is <class 'str'>\n",
      "\t*-> input is a String; converting to IDs first...\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "================================================================================\n",
      "2. text_ids => to_ids\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\t-> Input is already IDs... skipping conversion\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "================================================================================\n",
      "3. text_oh => to_ids\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\t-> input is One-Hot Encoded; converting to IDs first...\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "OK: to_ids passed\n"
     ]
    }
   ],
   "source": [
    "test_conversion_func(config.EMBED.to_ids, test_list, test_list[1].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conversion to One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Testing to_onehot:\n",
      "================================================================================\n",
      "1. text_str => to_onehot\n",
      "# to_onehot -> input is <class 'str'>\n",
      "# to_ids -> input is <class 'str'>\n",
      "\t*-> input is a String; converting to IDs first...\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "================================================================================\n",
      "2. text_ids => to_onehot\n",
      "# to_onehot -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\t-> Input is already IDs... skipping conversion\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "================================================================================\n",
      "3. text_oh => to_onehot\n",
      "# to_onehot -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "# to_ids -> input is <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\t-> input is One-Hot Encoded; converting to IDs first...\n",
      "------------------------------------------------------------\n",
      "  - Checking Types\n",
      "  - Checking Values\n",
      "OK: to_onehot passed\n"
     ]
    }
   ],
   "source": [
    "test_conversion_func(config.EMBED.to_onehot, test_list, test_list[2].value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}